{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e77f884-2ed2-433d-a339-bd8da38f104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c870d5-9036-4f0f-93ae-0870b2c1ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fa9f98-e1df-47dc-acc0-0b7440cadf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f42d8f-cb9b-4db9-a3ce-66026a4c0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Flatten()(base_model.output)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "# x=Dense(1024,activation='relu')(x)\n",
    "# x=Dense(512,activation='relu')(x)\n",
    "output=Dense(2,activation='softmax')(x)\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cd9582-015b-4dee-af4f-ee713f3f2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5028 images belonging to 2 classes.\n",
      "Found 1435 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\archive\\animal\\Train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\archive\\animal\\val', target_size=(224, 224), batch_size=32, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f1d05e-4e58-46e2-b1f4-8818844e2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 596s 4s/step - loss: 0.7345 - accuracy: 0.8673 - val_loss: 0.1893 - val_accuracy: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19964a82500>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(training_set,epochs=1,validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a66ffe7-2b3b-48f5-a963-078f1c0c2818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 2532s 16s/step - loss: 0.2815 - accuracy: 0.8874 - val_loss: 0.1466 - val_accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1990050e8c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(training_set,epochs=1,validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb12bb7d-4122-45ab-a0a4-b8d6e1bcc902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "[[1. 0.]]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\pexels-ezz7-691583.jpg',target_size=(224,224))\n",
    "img=image.img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "result=model.predict(img)\n",
    "print(result)\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\dog.jpeg',target_size=(224,224))\n",
    "img=image.img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "result=model.predict(img)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c67f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 1\n",
      "It is Dog\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted_class = np.argmax(result)  # This will give the index of the class with the highest probability\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "\n",
    "if(predicted_class==0):\n",
    "    print(\"It is Cat\")\n",
    "else:\n",
    "    print(\"It is Dog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fee7862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bprat\\OneDrive\\Desktop\\python\\python\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ddc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1= load_model(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\my_model.h5')\n",
    "\n",
    "img = image.load_img(r'C:\\Users\\bprat\\OneDrive\\Desktop\\DL\\dog.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "result = model1.predict(img)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
