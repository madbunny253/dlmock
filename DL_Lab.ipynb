{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA9n_eOkWcz3",
        "outputId": "e5ca5ce2-07a0-4863-aa0e-2a8dca261191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DL Lab\n"
          ]
        }
      ],
      "source": [
        "print(\"DL Lab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz5Mr4g4jEcT",
        "outputId": "230faa67-6389-453c-810b-e1e6e4068af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzIwdEcGZ51x"
      },
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rct5N-iaSAl"
      },
      "source": [
        "TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDtDL45DZ4pG",
        "outputId": "b80bd21c-039b-46eb-f768-535b199b3fa2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.4946 - loss: 0.7166\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4876 - loss: 0.6972 \n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5314 - loss: 0.6921 \n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5219 - loss: 0.6914 \n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.6839 \n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5333 - loss: 0.6894 \n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5256 - loss: 0.6898 \n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5590 - loss: 0.6833 \n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 0.6857 \n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 0.6833\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5569 - loss: 0.6829\n",
            "TensorFlow - Loss: 0.6827589869499207, Accuracy: 0.5580000281333923\n"
          ]
        }
      ],
      "source": [
        "#Tensorflow implementation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate some dummy data\n",
        "X = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
        "y = np.random.randint(2, size=(1000, 1))  # Binary targets\n",
        "\n",
        "# Define a simple Sequential model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(10,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f'TensorFlow - Loss: {loss}, Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70XUhfA6aT8Z"
      },
      "source": [
        "Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDVi27c0aCym",
        "outputId": "67a426d2-72c8-4a41-e747-032fa8c7c2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6851254105567932\n",
            "Epoch 2, Loss: 0.6946329474449158\n",
            "Epoch 3, Loss: 0.7138416171073914\n",
            "Epoch 4, Loss: 0.6775593757629395\n",
            "Epoch 5, Loss: 0.7061393857002258\n",
            "Epoch 6, Loss: 0.7237228155136108\n",
            "Epoch 7, Loss: 0.5972021222114563\n",
            "Epoch 8, Loss: 0.6808435916900635\n",
            "Epoch 9, Loss: 0.605871856212616\n",
            "Epoch 10, Loss: 0.7470676898956299\n",
            "PyTorch - Accuracy: 0.5979999899864197\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Generate some dummy data\n",
        "X = torch.randn(1000, 10)  # 1000 samples, 10 features each\n",
        "y = torch.randint(0, 2, (1000, 1), dtype=torch.float32)  # Binary targets\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convert data to a DataLoader for batching\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):  # 10 epochs\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(batch_X)  # Forward pass\n",
        "        loss = criterion(outputs, batch_y)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate the model (basic example using entire dataset)\n",
        "with torch.no_grad():\n",
        "    outputs = model(X)\n",
        "    predictions = (outputs > 0.5).float()\n",
        "    accuracy = (predictions == y).float().mean()\n",
        "    print(f'PyTorch - Accuracy: {accuracy.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLTPkskiarXn"
      },
      "source": [
        "# 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXtD9pWaq31",
        "outputId": "443ffffc-0236-4ced-f468-36a790634cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.4865 - val_accuracy: 0.9580 - val_loss: 0.1369\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1189 - val_accuracy: 0.9639 - val_loss: 0.1165\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0759 - val_accuracy: 0.9707 - val_loss: 0.0933\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0569 - val_accuracy: 0.9750 - val_loss: 0.0866\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0414 - val_accuracy: 0.9735 - val_loss: 0.0938\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0355 - val_accuracy: 0.9737 - val_loss: 0.0941\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0286 - val_accuracy: 0.9743 - val_loss: 0.0987\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0225 - val_accuracy: 0.9735 - val_loss: 0.1081\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0228 - val_accuracy: 0.9765 - val_loss: 0.1040\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0191 - val_accuracy: 0.9743 - val_loss: 0.1085\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.1247\n",
            "Test accuracy: 0.9731000065803528\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 2. Preprocess the data\n",
        "# Normalize the pixel values (0 to 255) to (0 to 1)\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Convert the labels to one-hot encoded format\n",
        "y_train = to_categorical(y_train, 10)  # 10 classes (digits 0-9)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 3. Define the feedforward neural network (FFNN)\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the 28x28 images into a single 784-dimensional vector\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add a fully connected layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add another fully connected layer with 64 neurons and ReLU activation\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer with 10 neurons (for each digit 0-9) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 6. Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5mOMr70a99j"
      },
      "source": [
        "# 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ3kan0haWzM",
        "outputId": "1ff8ce56-c1d9-4b41-acb6-e040feaa6ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2498 - loss: 2.0558 - val_accuracy: 0.3771 - val_loss: 1.7541\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3805 - loss: 1.7154 - val_accuracy: 0.4048 - val_loss: 1.6825\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4170 - loss: 1.6353 - val_accuracy: 0.4211 - val_loss: 1.6166\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4363 - loss: 1.5640 - val_accuracy: 0.4228 - val_loss: 1.6281\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4590 - loss: 1.5186 - val_accuracy: 0.4361 - val_loss: 1.5725\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4712 - loss: 1.4801 - val_accuracy: 0.4491 - val_loss: 1.5625\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4811 - loss: 1.4513 - val_accuracy: 0.4597 - val_loss: 1.5482\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4912 - loss: 1.4128 - val_accuracy: 0.4622 - val_loss: 1.5315\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5116 - loss: 1.3740 - val_accuracy: 0.4495 - val_loss: 1.5470\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5110 - loss: 1.3641 - val_accuracy: 0.4778 - val_loss: 1.4811\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4855 - loss: 1.4605\n",
            "Test accuracy: 0.47699999809265137\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load the CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 2. Preprocess the data\n",
        "# Normalize the images from range [0, 255] to [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # 10 classes in CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 3. Define the feedforward neural network\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the 32x32x3 images into a 1D vector of 3072 (32*32*3)\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# Add a fully connected layer with 512 neurons and ReLU activation\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add another fully connected layer with 256 neurons and ReLU activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Add another fully connected layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer with 10 neurons (for each class) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# 6. Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih93EikRbaY3"
      },
      "source": [
        "# 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN932-a-bZV0",
        "outputId": "19d92264-a2ae-49dd-c5b8-ab814552f70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 57ms/step - accuracy: 0.6740 - loss: 0.9007 - val_accuracy: 0.8479 - val_loss: 0.4102\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.8314 - loss: 0.4634 - val_accuracy: 0.8698 - val_loss: 0.3497\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.8598 - loss: 0.3888 - val_accuracy: 0.8836 - val_loss: 0.3159\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 54ms/step - accuracy: 0.8743 - loss: 0.3472 - val_accuracy: 0.8917 - val_loss: 0.2887\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 53ms/step - accuracy: 0.8821 - loss: 0.3257 - val_accuracy: 0.8942 - val_loss: 0.2806\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.8881 - loss: 0.3074 - val_accuracy: 0.9028 - val_loss: 0.2574\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.8950 - loss: 0.2859 - val_accuracy: 0.9047 - val_loss: 0.2602\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.8983 - loss: 0.2752 - val_accuracy: 0.9048 - val_loss: 0.2516\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.9042 - loss: 0.2627 - val_accuracy: 0.9080 - val_loss: 0.2445\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.9060 - loss: 0.2526 - val_accuracy: 0.9091 - val_loss: 0.2411\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9041 - loss: 0.2592\n",
            "Test accuracy: 0.9045000076293945\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load the Fashion MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# 2. Preprocess the data\n",
        "# Reshape data to include a single channel (grayscale)\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# Normalize pixel values from [0, 255] to [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoded format\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 3. Define the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a Conv2D layer with 32 filters, 3x3 kernel, ReLU activation, and input shape of 28x28x1\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "# Add a MaxPooling2D layer with a pool size of 2x2\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add another Conv2D layer with 64 filters and 3x3 kernel\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add another MaxPooling2D layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the feature maps into a 1D vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 neurons\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with 10 neurons (for each class) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# 6. Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n=50\n",
        "plt.imshow(X_test[n])\n",
        "plt.show()\n",
        "predicted_value = model.predict(X_test)\n",
        "plt.imshow(X_test[n])\n",
        "plt.show()\n",
        "print('Prediction:',predicted_value[n].argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "mHTWCB6Z6xpY",
        "outputId": "092959bb-61bb-4d92-c63e-19f9808333b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMqDrJAPbfBL"
      },
      "source": [
        "# 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kekGXrpbMZG",
        "outputId": "03555f81-69db-4d7a-9098-538a10853be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 15s/step - accuracy: 0.5465 - loss: 0.6893 - val_accuracy: 0.4896 - val_loss: 0.6867\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6882"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.5000 - loss: 0.6882 - val_accuracy: 0.7500 - val_loss: 0.6592\n",
            "Epoch 3/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 329ms/step - accuracy: 0.5392 - loss: 0.6815 - val_accuracy: 0.5677 - val_loss: 0.6711\n",
            "Epoch 4/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6875 - loss: 0.6142 - val_accuracy: 0.6250 - val_loss: 0.6350\n",
            "Epoch 5/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 274ms/step - accuracy: 0.6110 - loss: 0.6532 - val_accuracy: 0.5104 - val_loss: 0.6738\n",
            "Epoch 6/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5938 - loss: 0.6665 - val_accuracy: 0.6250 - val_loss: 0.6143\n",
            "Epoch 7/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.7077 - loss: 0.5959 - val_accuracy: 0.5625 - val_loss: 0.6153\n",
            "Epoch 8/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7500 - loss: 0.5923 - val_accuracy: 0.6250 - val_loss: 0.5327\n",
            "Epoch 9/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 273ms/step - accuracy: 0.7207 - loss: 0.5602 - val_accuracy: 0.5729 - val_loss: 0.6523\n",
            "Epoch 10/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.5489 - val_accuracy: 0.6250 - val_loss: 0.4969\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.6196 - loss: 0.6138\n",
            "Test accuracy: 0.6299999952316284\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Define the directory paths for training and testing data\n",
        "train_dir = '/content/drive/MyDrive/BE STUDY/DL/Dataset/chest_xray/train'\n",
        "test_dir = '/content/drive/MyDrive/BE STUDY/DL/Dataset/chest_xray/test'\n",
        "\n",
        "# 2. Preprocess the data using ImageDataGenerator\n",
        "# Apply image augmentation to avoid overfitting and to improve generalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values (scale images to [0,1])\n",
        "    rotation_range=20,  # Rotate images by up to 20 degrees\n",
        "    width_shift_range=0.2,  # Translate images horizontally by up to 20%\n",
        "    height_shift_range=0.2,  # Translate images vertically by up to 20%\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom in/out by 20%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Test data doesn't require augmentation, but we normalize the pixel values\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3. Create the data generators for loading images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # Binary classification (Normal vs Pneumonia)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# 4. Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second Conv2D layer with 64 filters and 3x3 kernel\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Third Conv2D layer with 128 filters and 3x3 kernel\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Fourth Conv2D layer with 128 filters and 3x3 kernel\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output from the Conv2D layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer with 512 units and ReLU activation\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add dropout for regularization to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with 1 neuron and sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,  # Train for 10 epochs (adjust as needed)\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // test_generator.batch_size\n",
        ")\n",
        "\n",
        "# 7. Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4lRHg-Ri8yi"
      },
      "source": [
        "# 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MBllRusRm6"
      },
      "source": [
        "Dataset download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38liNZFSsVQK"
      },
      "source": [
        "actual code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJGSBqsIi8fr",
        "outputId": "c3e2a9cc-4da0-415e-9139-cc39e555edc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 404 images belonging to 4 classes.\n",
            "Found 164 images belonging to 4 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 13s/step - accuracy: 0.2714 - loss: 1.3977 - val_accuracy: 0.2750 - val_loss: 1.3820\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.1875 - loss: 1.4080 - val_accuracy: 0.5000 - val_loss: 1.3512\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 378ms/step - accuracy: 0.2919 - loss: 1.3805 - val_accuracy: 0.2688 - val_loss: 1.3683\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.2000 - loss: 1.3918 - val_accuracy: 0.0000e+00 - val_loss: 1.4053\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - accuracy: 0.3378 - loss: 1.3600 - val_accuracy: 0.4000 - val_loss: 1.3478\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.3552 - val_accuracy: 0.7500 - val_loss: 1.3058\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.3764 - loss: 1.3343 - val_accuracy: 0.3875 - val_loss: 1.3097\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5000 - loss: 1.2230 - val_accuracy: 0.7500 - val_loss: 1.0161\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 366ms/step - accuracy: 0.4124 - loss: 1.2406 - val_accuracy: 0.3625 - val_loss: 1.2881\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 1.3072 - val_accuracy: 0.5000 - val_loss: 1.0396\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.3480 - loss: 1.2751\n",
            "Test accuracy: 0.35975611209869385\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Define the directory paths for training and testing data\n",
        "train_dir = '/content/drive/MyDrive/BE STUDY/DL/Dataset/food_dataset/training'\n",
        "test_dir = '/content/drive/MyDrive/BE STUDY/DL/Dataset/food_dataset/evaluation'\n",
        "\n",
        "# 2. Preprocess the data using ImageDataGenerator\n",
        "# Apply image augmentation to avoid overfitting and to improve generalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values (scale images to [0,1])\n",
        "    rotation_range=20,  # Rotate images by up to 20 degrees\n",
        "    width_shift_range=0.2,  # Translate images horizontally by up to 20%\n",
        "    height_shift_range=0.2,  # Translate images vertically by up to 20%\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom in/out by 20%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Test data doesn't require augmentation, but we normalize the pixel values\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3. Create the data generators for loading images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Multiclass classification for food categories\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 4. Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second Conv2D layer with 64 filters and 3x3 kernel\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Third Conv2D layer with 128 filters and 3x3 kernel\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Fourth Conv2D layer with 128 filters and 3x3 kernel\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output from the Conv2D layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer with 512 units and ReLU activation\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add dropout for regularization to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with units equal to the number of food categories and softmax activation\n",
        "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,  # Train for 10 epochs (adjust as needed)\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // test_generator.batch_size\n",
        ")\n",
        "\n",
        "# 7. Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "llRGOXebAx0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3okserb02H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss function (Mean Squared Error)\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# RNN Class using NumPy\n",
        "class RNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
        "        # Initialize weights\n",
        "        self.hidden_size = hidden_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Input to hidden layer weights\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        # Hidden to hidden (recurrent) weights\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        # Hidden to output layer weights\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        # Biases for the hidden and output layers\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h_prev = np.zeros((self.hidden_size, 1))  # Initialize hidden state\n",
        "        self.hs = {}  # Store all hidden states\n",
        "        self.hs[-1] = h_prev  # Set the initial hidden state\n",
        "\n",
        "        outputs = []  # Store all outputs\n",
        "\n",
        "        for t, x in enumerate(inputs):\n",
        "            # Reshape input x into a column vector\n",
        "            x = x.reshape(-1, 1)\n",
        "\n",
        "            # Compute the hidden state\n",
        "            h_current = sigmoid(np.dot(self.Wxh, x) + np.dot(self.Whh, h_prev) + self.bh)\n",
        "            # Compute the output\n",
        "            y = np.dot(self.Why, h_current) + self.by\n",
        "\n",
        "            # Store the hidden state and output\n",
        "            self.hs[t] = h_current\n",
        "            outputs.append(y)\n",
        "\n",
        "            # Update hidden state\n",
        "            h_prev = h_current\n",
        "\n",
        "        return np.array(outputs)\n",
        "\n",
        "    def backward(self, inputs, targets):\n",
        "        # Initialize gradients for weight and bias matrices\n",
        "        dWxh, dWhh, dWhy = np.zeros_like(self.Wxh), np.zeros_like(self.Whh), np.zeros_like(self.Why)\n",
        "        dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n",
        "        dh_next = np.zeros((self.hidden_size, 1))\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # Iterate over the inputs in reverse order for backpropagation through time\n",
        "        for t in reversed(range(len(inputs))):\n",
        "            # Reshape the input and target\n",
        "            x = inputs[t].reshape(-1, 1)\n",
        "            y_true = targets[t].reshape(-1, 1)\n",
        "\n",
        "            # Calculate loss\n",
        "            y_pred = np.dot(self.Why, self.hs[t]) + self.by\n",
        "            loss += mse_loss(y_true, y_pred)\n",
        "\n",
        "            # Gradient of the output layer (dL/dy_pred)\n",
        "            dy = y_pred - y_true\n",
        "\n",
        "            # Gradients for Why and by\n",
        "            dWhy += np.dot(dy, self.hs[t].T)\n",
        "            dby += dy\n",
        "\n",
        "            # Backpropagate into hidden layer\n",
        "            dh = np.dot(self.Why.T, dy) + dh_next\n",
        "            dh_raw = dh * sigmoid_derivative(self.hs[t])\n",
        "\n",
        "            # Gradients for Wxh, Whh, and bh\n",
        "            dWxh += np.dot(dh_raw, x.T)\n",
        "            dWhh += np.dot(dh_raw, self.hs[t-1].T)\n",
        "            dbh += dh_raw\n",
        "\n",
        "            # Update next dh for backpropagation\n",
        "            dh_next = np.dot(self.Whh.T, dh_raw)\n",
        "\n",
        "        # Clip gradients to avoid exploding gradients\n",
        "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "            np.clip(dparam, -1, 1, out=dparam)\n",
        "\n",
        "        # Update weights and biases using gradient descent\n",
        "        self.Wxh -= self.learning_rate * dWxh\n",
        "        self.Whh -= self.learning_rate * dWhh\n",
        "        self.Why -= self.learning_rate * dWhy\n",
        "        self.bh -= self.learning_rate * dbh\n",
        "        self.by -= self.learning_rate * dby\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train(self, inputs, targets, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            # Forward pass\n",
        "            outputs = self.forward(inputs)\n",
        "\n",
        "            # Backward pass\n",
        "            loss = self.backward(inputs, targets)\n",
        "\n",
        "            # Print the loss every 10 epochs\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "# Sample sequence prediction task\n",
        "# Input: [0, 1, 2, 3, 4]\n",
        "# Target: [1, 2, 3, 4, 5] (predict the next number in the sequence)\n",
        "\n",
        "inputs = np.array([[0], [1], [2], [3], [4]])\n",
        "targets = np.array([[1], [2], [3], [4], [5]])\n",
        "\n",
        "# Initialize the RNN with input_size=1, hidden_size=10, output_size=1\n",
        "rnn = RNN(input_size=1, hidden_size=10, output_size=1)\n",
        "\n",
        "# Train the RNN on the sequence for 100 epochs\n",
        "rnn.train(inputs, targets, epochs=100)\n",
        "\n",
        "# Test the trained model on a new sequence\n",
        "test_inputs = np.array([[5], [6], [7], [8], [9]])\n",
        "predictions = rnn.forward(test_inputs)\n",
        "\n",
        "# Print predictions\n",
        "print(\"Predictions: \")\n",
        "print(predictions.flatten())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoEncoder"
      ],
      "metadata": {
        "id": "1ML1-EmdAzyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load and preprocess the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], -1))  # Flatten 28x28 images into 784-dim vectors\n",
        "x_test = x_test.reshape((x_test.shape[0], -1))\n",
        "\n",
        "# 2. Build the autoencoder architecture\n",
        "input_dim = x_train.shape[1]  # 784 (28x28)\n",
        "encoding_dim = 64  # Number of neurons in the encoding layer\n",
        "\n",
        "# Input layer\n",
        "input_img = Input(shape=(input_dim,))\n",
        "\n",
        "# Encoding layer with sparsity constraint (activity_regularizer)\n",
        "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "\n",
        "# Decoding layer\n",
        "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# 3. Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# 4. Train the model\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# 5. Evaluate the reconstruction performance\n",
        "reconstructed_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Visualize original and reconstructed images\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(reconstructed_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "E63Jz6w0A1ge",
        "outputId": "58c9c209-6daf-407d-bd75-a4a53d890379"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.6909 - val_loss: 0.6155\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.5988 - val_loss: 0.5535\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.5400 - val_loss: 0.5038\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4925 - val_loss: 0.4638\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.4548 - val_loss: 0.4314\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.4239 - val_loss: 0.4050\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3988 - val_loss: 0.3834\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3786 - val_loss: 0.3656\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3612 - val_loss: 0.3508\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3471 - val_loss: 0.3385\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3353 - val_loss: 0.3281\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3254 - val_loss: 0.3194\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3174 - val_loss: 0.3120\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3103 - val_loss: 0.3056\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3044 - val_loss: 0.3002\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2989 - val_loss: 0.2955\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2945 - val_loss: 0.2915\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2908 - val_loss: 0.2880\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2872 - val_loss: 0.2850\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2841 - val_loss: 0.2823\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2820 - val_loss: 0.2800\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2796 - val_loss: 0.2780\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2774 - val_loss: 0.2762\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2760 - val_loss: 0.2746\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2746 - val_loss: 0.2733\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2731 - val_loss: 0.2721\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2718 - val_loss: 0.2710\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2709 - val_loss: 0.2700\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2698 - val_loss: 0.2692\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2693 - val_loss: 0.2685\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2687 - val_loss: 0.2678\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2682 - val_loss: 0.2672\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2673 - val_loss: 0.2667\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2669 - val_loss: 0.2663\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2664 - val_loss: 0.2658\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.2656 - val_loss: 0.2655\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2654 - val_loss: 0.2652\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2653 - val_loss: 0.2649\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2649 - val_loss: 0.2646\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.2653 - val_loss: 0.2644\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2646 - val_loss: 0.2642\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2640 - val_loss: 0.2640\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2645 - val_loss: 0.2638\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.2641 - val_loss: 0.2637\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2639 - val_loss: 0.2636\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2639 - val_loss: 0.2635\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2634 - val_loss: 0.2634\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2638 - val_loss: 0.2633\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2638 - val_loss: 0.2632\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2633 - val_loss: 0.2631\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# After reconstructing the test images\n",
        "reconstructed_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Compute Mean Squared Error (MSE) for each image\n",
        "mse_values = np.mean(np.square(x_test - reconstructed_imgs), axis=1)\n",
        "\n",
        "# Compute the overall MSE for the test dataset\n",
        "mse_score = np.mean(mse_values)\n",
        "\n",
        "print(f\"Mean Squared Error (Reconstruction Accuracy): {mse_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXZz307XBHWf",
        "outputId": "5a0af014-9b3f-4c09-ac73-514260de5a7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Mean Squared Error (Reconstruction Accuracy): 0.0675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-hub tensorflow-datasets matplotlib opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q0fMMwNCEQ4",
        "outputId": "dd258df2-0e0b-4c92-acd0-5c03e12be55c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (16.1.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.5)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.9.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.20.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# 1. Load COCO dataset (or any dataset from TensorFlow Datasets)\n",
        "# We'll use a small subset for demonstration.\n",
        "(ds_train, ds_test), ds_info = tfds.load('coco/2017', split=['train[:1%]', 'validation[:1%]'], with_info=True)\n",
        "\n",
        "# 2. Load the pre-trained Faster R-CNN model from TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\"\n",
        "detector = hub.load(model_url)\n",
        "\n",
        "# 3. Define a function to visualize the detections\n",
        "def draw_boxes_on_image(image, boxes, class_ids, scores, class_names, score_threshold=0.5):\n",
        "    image_with_boxes = image.copy()\n",
        "    h, w, _ = image_with_boxes.shape\n",
        "    for box, class_id, score in zip(boxes, class_ids, scores):\n",
        "        if score >= score_threshold:\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "            (left, right, top, bottom) = (xmin * w, xmax * w, ymin * h, ymax * h)\n",
        "            cv2.rectangle(image_with_boxes, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n",
        "            label = f'{class_names[class_id]}: {score:.2f}'\n",
        "            cv2.putText(image_with_boxes, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "    return image_with_boxes\n",
        "\n",
        "# 4. Function to perform detection on a single image\n",
        "def detect_objects(image, detector):\n",
        "    converted_img = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
        "    detections = detector(converted_img)\n",
        "\n",
        "    # Extract the detection results\n",
        "    boxes = detections['detection_boxes'][0].numpy()\n",
        "    class_ids = detections['detection_classes'][0].numpy().astype(np.int32)\n",
        "    scores = detections['detection_scores'][0].numpy()\n",
        "\n",
        "    return boxes, class_ids, scores\n",
        "\n",
        "# 5. Run object detection on a few images from the COCO dataset\n",
        "class_names = ds_info.features['objects']['label'].names\n",
        "\n",
        "for sample in ds_test.take(5):  # Taking 5 images from the test set\n",
        "    image = sample['image'].numpy()\n",
        "    boxes, class_ids, scores = detect_objects(image, detector)\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    image_with_boxes = draw_boxes_on_image(image, boxes, class_ids, scores, class_names)\n",
        "\n",
        "    # Display the result\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_with_boxes)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "9fafa151cde74976a16602d2ad3b07e4",
            "6700aafd5b214e9ab1414a43c0d5d26e",
            "9fb86a6863ff4b58add52e7f6719cf2a",
            "724c841486c0417091b3acc0a4cfb318",
            "adcf6be78b914893a46cc8a190be745e",
            "7d8bd476a00243e0b4e335ad89ccbbe7",
            "8fd39e6bfb2947c6811f52e87cb03dcd",
            "725058ed5b8c4d07a93e1b19bdebffad",
            "9791f715f6824ce5abde06738e421116",
            "adfb0ba49993476b878362e698e133ce",
            "cc04d183919840d2975118430a56b721",
            "8e28b9bebcd0475fa2bafd04e46604ad",
            "567e73f987e34d1eb6be53bd0fba634f",
            "07402118d9f34e7e9a136bcfd6f1b839",
            "fcd0d8a6ddb74708803e6649131be8e5",
            "323b4579967f4168b9211e5cbe2502f5",
            "35a668c4508e4404ba28a022d7fac1bf",
            "baea9e1d047d4066919486b6f8eba186",
            "946e10cedb6945d996203c61b0ed7e32",
            "601220323a9945988aad08e10cf58cd2",
            "a8ce458b3fb94c13a6b9b72bbb7aefa5",
            "ad58b730cdb94502989e585143cfb067",
            "2a00d07e2e18455eae42340d29af3716",
            "120d94d1f2dd41d6aea268693371d403",
            "4886924ea40a4662bc0fdb8765be012b",
            "c2b6f215348140c68dec4e387532e232",
            "53afda231a124dbbaef5abfeadc9ecfc",
            "5ea3e3faa34c4cf780c0f74c6094ed9a",
            "21daa2e31a104059825d0c9fb4334833",
            "a485207accfc4c8db7ade6969a6931b3",
            "ee756609df7e4b91bbbcee3899544c02",
            "a5a53318b09845e6ae31c7b4e6f4bebd",
            "46ab01e796fc4891b8e3cf7c746a3945"
          ]
        },
        "id": "qywr3JjwC6Z6",
        "outputId": "d4a62b36-185d-448f-d9b1-1cce3f80f978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 25.20 GiB (download: 25.20 GiB, generated: Unknown size, total: 25.20 GiB) to /root/tensorflow_datasets/coco/2017/1.1.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fafa151cde74976a16602d2ad3b07e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e28b9bebcd0475fa2bafd04e46604ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a00d07e2e18455eae42340d29af3716"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qutOS0LyDGwi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fafa151cde74976a16602d2ad3b07e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6700aafd5b214e9ab1414a43c0d5d26e",
              "IPY_MODEL_9fb86a6863ff4b58add52e7f6719cf2a",
              "IPY_MODEL_724c841486c0417091b3acc0a4cfb318"
            ],
            "layout": "IPY_MODEL_adcf6be78b914893a46cc8a190be745e"
          }
        },
        "6700aafd5b214e9ab1414a43c0d5d26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8bd476a00243e0b4e335ad89ccbbe7",
            "placeholder": "​",
            "style": "IPY_MODEL_8fd39e6bfb2947c6811f52e87cb03dcd",
            "value": "Dl Completed...:  80%"
          }
        },
        "9fb86a6863ff4b58add52e7f6719cf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725058ed5b8c4d07a93e1b19bdebffad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9791f715f6824ce5abde06738e421116",
            "value": 1
          }
        },
        "724c841486c0417091b3acc0a4cfb318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfb0ba49993476b878362e698e133ce",
            "placeholder": "​",
            "style": "IPY_MODEL_cc04d183919840d2975118430a56b721",
            "value": " 5/5 [22:58&lt;00:00, 234.84s/ url]"
          }
        },
        "adcf6be78b914893a46cc8a190be745e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8bd476a00243e0b4e335ad89ccbbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd39e6bfb2947c6811f52e87cb03dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725058ed5b8c4d07a93e1b19bdebffad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9791f715f6824ce5abde06738e421116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adfb0ba49993476b878362e698e133ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc04d183919840d2975118430a56b721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e28b9bebcd0475fa2bafd04e46604ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567e73f987e34d1eb6be53bd0fba634f",
              "IPY_MODEL_07402118d9f34e7e9a136bcfd6f1b839",
              "IPY_MODEL_fcd0d8a6ddb74708803e6649131be8e5"
            ],
            "layout": "IPY_MODEL_323b4579967f4168b9211e5cbe2502f5"
          }
        },
        "567e73f987e34d1eb6be53bd0fba634f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35a668c4508e4404ba28a022d7fac1bf",
            "placeholder": "​",
            "style": "IPY_MODEL_baea9e1d047d4066919486b6f8eba186",
            "value": "Dl Size...:  72%"
          }
        },
        "07402118d9f34e7e9a136bcfd6f1b839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_946e10cedb6945d996203c61b0ed7e32",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_601220323a9945988aad08e10cf58cd2",
            "value": 1
          }
        },
        "fcd0d8a6ddb74708803e6649131be8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ce458b3fb94c13a6b9b72bbb7aefa5",
            "placeholder": "​",
            "style": "IPY_MODEL_ad58b730cdb94502989e585143cfb067",
            "value": " 25799/25799 [22:58&lt;00:00, 54.61 MiB/s]"
          }
        },
        "323b4579967f4168b9211e5cbe2502f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a668c4508e4404ba28a022d7fac1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baea9e1d047d4066919486b6f8eba186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "946e10cedb6945d996203c61b0ed7e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "601220323a9945988aad08e10cf58cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ce458b3fb94c13a6b9b72bbb7aefa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad58b730cdb94502989e585143cfb067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a00d07e2e18455eae42340d29af3716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_120d94d1f2dd41d6aea268693371d403",
              "IPY_MODEL_4886924ea40a4662bc0fdb8765be012b",
              "IPY_MODEL_c2b6f215348140c68dec4e387532e232"
            ],
            "layout": "IPY_MODEL_53afda231a124dbbaef5abfeadc9ecfc"
          }
        },
        "120d94d1f2dd41d6aea268693371d403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea3e3faa34c4cf780c0f74c6094ed9a",
            "placeholder": "​",
            "style": "IPY_MODEL_21daa2e31a104059825d0c9fb4334833",
            "value": "Extraction completed...:  86%"
          }
        },
        "4886924ea40a4662bc0fdb8765be012b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a485207accfc4c8db7ade6969a6931b3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee756609df7e4b91bbbcee3899544c02",
            "value": 1
          }
        },
        "c2b6f215348140c68dec4e387532e232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a53318b09845e6ae31c7b4e6f4bebd",
            "placeholder": "​",
            "style": "IPY_MODEL_46ab01e796fc4891b8e3cf7c746a3945",
            "value": " 141245/163965 [22:58&lt;00:32, 689.14 file/s]"
          }
        },
        "53afda231a124dbbaef5abfeadc9ecfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea3e3faa34c4cf780c0f74c6094ed9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21daa2e31a104059825d0c9fb4334833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a485207accfc4c8db7ade6969a6931b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ee756609df7e4b91bbbcee3899544c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a53318b09845e6ae31c7b4e6f4bebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ab01e796fc4891b8e3cf7c746a3945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}